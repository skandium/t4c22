{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from h3 import h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_preprocessed_counters, load_supersegments, create_nodes_with_counters, \\\n",
    "    append_static_pred_relative_to_df, create_multi_traffic_state, split_train_valid, merge_pcas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix paths and other global variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Users/andrei/Desktop/data4cast/data/\")\n",
    "# data_dir = Path(\"/Users/martin/PycharmProjects/traffic4cast/data/\")\n",
    "\n",
    "city_name = \"madrid\"\n",
    "model_name = \"extended_sota_previous\"\n",
    "\n",
    "CACHED = True\n",
    "FULL_TRAIN = True\n",
    "\n",
    "NEIGHBORS_FOR_WEIGHTING = 10\n",
    "H3_RES = 6\n",
    "\n",
    "# In submission, only got to set USE_SPEED_FEATURES=True for Melbourne.\n",
    "#  We used USE_SPEED_FEATURES=False for Madrid, London.\n",
    "USE_SPEED_FEATURES = True\n",
    "\n",
    "# In submission, only got to set USE_ADVANCED_QUANTILES=True for London and Melbourne.\n",
    "#  We used USE_ADVANCED_QUANTILES=False for Madrid.\n",
    "USE_ADVANCED_QUANTILES = True\n",
    "\n",
    "SAVE_MODEL_CHECKPOINTS = False\n",
    "\n",
    "# Default count of iters to use when FULL_TRAIN is False\n",
    "NO_LGB_ITERS = 800\n",
    "\n",
    "num_iters = {\n",
    "    \"london\": 5700,\n",
    "    \"madrid\": 4900,\n",
    "    \"melbourne\": 3200\n",
    "}\n",
    "\n",
    "num_leaves = {\n",
    "    \"london\": 400,\n",
    "    \"madrid\": 350,\n",
    "    \"melbourne\": 350\n",
    "}\n",
    "\n",
    "# valid_weeks_hardcoded represents the weeks to use for validation when FULL_TRAIN is False\n",
    "valid_weeks_hardcoded = {\n",
    "    # From [23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53]\n",
    "    \"melbourne\": [25, 33, 41, 49],\n",
    "    # From [22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52]\n",
    "    \"madrid\": [24, 32, 40, 48],\n",
    "    # From [27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51,  1,  3,  5]\n",
    "    \"london\": [29, 37, 45, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix static assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_parquet(data_dir / f\"road_graph/{city_name}/road_graph_nodes.parquet\")\n",
    "node_coordinates = nodes.groupby(\"node_id\")[[\"x\", \"y\"]].first().to_dict(orient=\"index\")\n",
    "node_to_lat_lng = nodes.set_index(\"node_id\")[[\"x\", \"y\"]].T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supersegments, supersegment_to_id, id_to_supersegment = load_supersegments(city_name, node_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_with_counters = create_nodes_with_counters(city_name, blacklist=True)\n",
    "nodes_with_counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create nearest counter features </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nearest counter for edges which are not immediately at counter\n",
    "from sklearn.neighbors import KDTree, BallTree\n",
    "tree = KDTree(nodes_with_counters[[\"x\", \"y\"]], metric=\"euclidean\")\n",
    "dist, ind = tree.query(supersegments[[\"x\", \"y\"]], k=NEIGHBORS_FOR_WEIGHTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supersegments[\"nearest_counter_id\"] = ind[:,0]\n",
    "# supersegments[\"nearest_counter_id\"] = supersegments[\"nearest_counter_id\"].astype(\"category\")\n",
    "supersegments[\"counter_distance_euclidean\"] = dist[:,0]\n",
    "supersegments[\"counter_distance_euclidean_mean_top5\"] = dist[:,:5].mean(axis=1)\n",
    "supersegments[\"counter_distance_euclidean_mean_all\"] = dist.mean(axis=1)\n",
    "supersegments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Utils for loading the train/test data and preparing them for downstream</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(city, mode=\"train\"):\n",
    "    counts = load_preprocessed_counters(city_name, mode)\n",
    "    \n",
    "    label_frames = []\n",
    "\n",
    "    if mode == \"train\":\n",
    "        files = sorted((data_dir / 'train' / city / 'labels').glob('eta_labels_*.parquet'))\n",
    "        for f in files:\n",
    "            label_frames.append(pd.read_parquet(f))\n",
    "        labels = pd.concat(label_frames)\n",
    "        print(labels.shape)\n",
    "    else:\n",
    "        labels = None\n",
    "            \n",
    "    return counts, labels\n",
    "\n",
    "def normalize_data(mode=\"train\"):\n",
    "    if mode == \"test\":\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    counts, labels = load_data(city_name, mode=mode)\n",
    "    labels[\"supersegment_id\"] = [supersegment_to_id[s] for s in labels[\"identifier\"]]\n",
    "    del labels[\"identifier\"]\n",
    "    # Get supersegment features like nearest_counter_id\n",
    "    labels = labels.merge(supersegments, on=\"supersegment_id\")\n",
    "\n",
    "    # Get counter_id of nodes\n",
    "    counts = counts.merge(nodes_with_counters[[\"node_id\", \"counter_id\"]], on=\"node_id\")\n",
    "    print(counts.shape)\n",
    "    \n",
    "    # Merge labels to nearest counters\n",
    "    labels = labels.merge(counts, left_on=[\"day\", \"t\", \"nearest_counter_id\"], right_on=[\"day\", \"t\", \"counter_id\"])\n",
    "    print(labels.shape)\n",
    "    # Note that some time windows don't have counter data!\n",
    "    # TODO left join, ignore nans?\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Util for H3 feature creation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h3_variable(data, mode=\"train\"):\n",
    "    counts = load_preprocessed_counters(city_name, mode)\n",
    "    # counts[\"volumes_median\"] = [np.median(v) for v in tqdm(counts[\"volumes_1h\"])]\n",
    "    counts[\"h3\"] = [h3.geo_to_h3(node_to_lat_lng[x][\"y\"], node_to_lat_lng[x][\"x\"], H3_RES) for x in tqdm(counts[\"node_id\"])]\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        counts_h3_volumes = counts.groupby([\"day\", \"t\", \"h3\"])[[\"volumes_mdn\"]].sum()\n",
    "    else:\n",
    "        counts_h3_volumes = counts.groupby([\"test_idx\", \"h3\"])[[\"volumes_mdn\"]].sum()\n",
    "        \n",
    "    time_hex_to_vol_dict = counts_h3_volumes.T.to_dict()\n",
    "    data[\"h3\"] = [h3.geo_to_h3(yy, xx, H3_RES) for xx, yy in tqdm(zip(data[\"x\"], data[\"y\"]))]\n",
    "    if mode == \"train\":\n",
    "        data[\"h3_vol\"] = [\n",
    "        time_hex_to_vol_dict.get(\n",
    "            (x, y, z), \n",
    "            {\"volumes_mdn\": np.nan}\n",
    "        )[\"volumes_mdn\"] \n",
    "        for x, y, z in tqdm(zip(data[\"day\"], data[\"t\"], data[\"h3\"]))]\n",
    "    else:\n",
    "        data[\"h3_vol\"] = [\n",
    "        time_hex_to_vol_dict.get(\n",
    "            (x, z), \n",
    "            {\"volumes_mdn\": np.nan}\n",
    "        )[\"volumes_mdn\"] \n",
    "        for x, z in tqdm(zip(data[\"test_idx\"], data[\"h3\"]))]\n",
    "    data[\"h3_vol\"] = data[\"h3_vol\"].fillna(data[\"h3_vol\"].median())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Loading prepared training data if cached, loading raw data and preparing it otherwise </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CACHED:\n",
    "    try:\n",
    "        data = pd.read_parquet(data_dir / \"traffic\" / city_name / \"data_all_h3.parquet\")\n",
    "        print(\"Loaded data\")\n",
    "    except FileNotFoundError:\n",
    "        data = normalize_data()\n",
    "        data = create_h3_variable(data)\n",
    "        data.to_parquet(data_dir / \"traffic\" / city_name / \"data_all_h3.parquet\")\n",
    "else:\n",
    "    data = normalize_data()\n",
    "    data = create_h3_variable(data)\n",
    "    data.to_parquet(data_dir / \"traffic\" / city_name / \"data_all_h3.parquet\")\n",
    "    \n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Appending PCA features </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merge_pcas(city_name, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training data (if FULL_TRAIN=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FULL_TRAIN:\n",
    "    train = data\n",
    "else:\n",
    "    train, valid = split_train_valid(city_name, data)\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ETA target encodings based on multiple granularities of conditional traffic quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traffic_quantiles_list = []\n",
    "\n",
    "base_quantiles = [10, 20, 30, 40, 50, 100]\n",
    "advanced_quantiles = [2, 4, 8, 10, 20, 30, 40, 50, 60, 80]\n",
    "\n",
    "if USE_ADVANCED_QUANTILES:\n",
    "    MULTI_LEVEL_QUANTILES = base_quantiles\n",
    "else:\n",
    "    MULTI_LEVEL_QUANTILES = advanced_quantiles\n",
    "\n",
    "MULTI_LEVEL_QUANTILES = [2, 4, 8, 10, 20, 30, 40, 50, 60, 80]\n",
    "\n",
    "\n",
    "for num_quantiles in tqdm(MULTI_LEVEL_QUANTILES):\n",
    "    traffic_quantiles = train.groupby([\"day\", \"t\"])[\"volumes_mdn\"].median().quantile(q=[i/num_quantiles for i in range(num_quantiles)])\n",
    "    traffic_quantiles_list.append(traffic_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, quantile_feats = create_multi_traffic_state(train, traffic_quantiles_list, \"volumes_mdn\", \"train\")\n",
    "if not FULL_TRAIN:\n",
    "    valid, _ = create_multi_traffic_state(valid, traffic_quantiles_list, \"volumes_mdn\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, quant_feature in tqdm(enumerate(quantile_feats)):\n",
    "    append_static_pred_relative_to_df(train, train, quant_feature, f\"static_pred_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_pred_feats = [f\"static_pred_{i}\" for i in range(len(quantile_feats))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FULL_TRAIN:\n",
    "    for i, quant_feature in tqdm(enumerate(quantile_feats)):\n",
    "        append_static_pred_relative_to_df(valid, train, quant_feature, f\"static_pred_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append speed features (if USE_SPEED_FEATURE = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SPEED_FEATURES:\n",
    "    supersegment_speed_features = pd.read_parquet(data_dir / \"traffic\" / city_name / \"ss_speeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # Edge position features\n",
    "    \"counter_distance_euclidean\",\n",
    "    \"counter_distance_euclidean_mean_all\",\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    \"supersegment_id\",\n",
    "    # Traffic features\n",
    "    # \"quantile\",\n",
    "    \"total_traffic\",\n",
    "    \"h3_vol\",\n",
    "    # \"city_volumes_gr\",\n",
    "    # \"city_volumes_sum\",\n",
    "    # \"h3\"\n",
    "] + [f for f in train.columns if f.startswith(\"PC\")] + quantile_feats[-1:] + static_pred_feats\n",
    "\n",
    "if USE_SPEED_FEATURES:\n",
    "    speed_feats = [\"dummy_eta\", \"dummy_eta_freeflow\", \"segment_count\", \"length\", \"lanes\"]\n",
    "    features = features + speed_feats\n",
    "\n",
    "label = \"eta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SPEED_FEATURES:\n",
    "    train = train.merge(supersegment_speed_features, left_on=\"supersegment_id\", right_index=True)\n",
    "    if not FULL_TRAIN:\n",
    "        valid = valid.merge(supersegment_speed_features, left_on=\"supersegment_id\", right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Prepare LGB Datasets and train the model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FULL_TRAIN:\n",
    "    lgb_set = lgb.Dataset(train[features], train[label], init_score=train[static_pred_feats[0]])\n",
    "else:\n",
    "    # create dataset for lightgbm\n",
    "    lgb_train = lgb.Dataset(train[features], train[label], init_score=train[static_pred_feats[0]])\n",
    "    lgb_eval = lgb.Dataset(valid[features], valid[label], reference=lgb_train, init_score=valid[static_pred_feats[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "SAVE_MODEL_CHECKPOINTS = False\n",
    "\n",
    "if SAVE_MODEL_CHECKPOINTS:\n",
    "    def save_model_callback(env):\n",
    "        if env.iteration % 100 == 0:\n",
    "            env.model.save_model(data_dir / \"models\" / model_name / city_name / f\"modelQ_{env.iteration}.lgb\")\n",
    "\n",
    "    callbacks.append(save_model_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "PRINT_TIME = True\n",
    "\n",
    "if PRINT_TIME:\n",
    "    def print_time(env):\n",
    "        print(time.time() - START_TIME)\n",
    "    \n",
    "    callbacks.append(print_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When training on the full data, will save evaluation time by only validating the model on a small data sample\n",
    "#  when USE_MOCK_VALIDATION_WHEN_FULL_TRAIN is True. Otherwise, will validate each time on the whole training dataset\n",
    "USE_MOCK_VALIDATION_WHEN_FULL_TRAIN = True\n",
    "SMALL_SAMPLE_SIZE = 20\n",
    "\n",
    "if USE_MOCK_VALIDATION_WHEN_FULL_TRAIN:\n",
    "    lgb_set_mock = lgb.Dataset(\n",
    "        data=train[:SMALL_SAMPLE_SIZE][features], \n",
    "        label=train[:SMALL_SAMPLE_SIZE][label], \n",
    "        init_score=train[:SMALL_SAMPLE_SIZE][static_pred_feats[0]]\n",
    "    )\n",
    "    lgb_val = lgb_set_mock\n",
    "else:\n",
    "    lgb_val = lgb_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Optuna\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'l1',\n",
    "    'num_leaves': num_leaves[city_name],\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 1.0,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'lambda_l1': 8.544245989665272,\n",
    "    'lambda_l2': 0.09577740930772316,\n",
    "    'min_child_samples': 10,\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "\n",
    "START_TIME = time.time()\n",
    "\n",
    "if FULL_TRAIN:\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_set,\n",
    "                    num_boost_round=num_iters[city_name],\n",
    "                    valid_sets=[lgb_val],\n",
    "                    callbacks=callbacks,\n",
    "                    verbose_eval=25)\n",
    "else:\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=NO_LGB_ITERS,\n",
    "                    valid_sets=[lgb_eval],\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=200)],\n",
    "                    verbose_eval=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain model predictions using SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "def shap_wrapped(data, model, features):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "\n",
    "    X = data.sample(500)print_timees]\n",
    "\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    shap.initjs()    \n",
    "    shap.summary_plot(shap_values, X)\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\")\n",
    "    \n",
    "shap_wrapped(train, gbm, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = data_dir / \"models\" / model_name / city_name / \"modelQ.lgb\"\n",
    "model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "gbm.save_model(model_path)\n",
    "print(f\"Saved {model_name} at {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using a saved artifact to do predictions:\n",
    "# gbm = lgb.Booster(model_file=data_dir / \"models\" / model_name / city_name / \"model.lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_left = pd.DataFrame({\"identifier\": list(supersegment_to_id.keys())})\n",
    "test_left = pd.concat([test_left]*100)\n",
    "test_idx = []\n",
    "current = 0\n",
    "unique_segments = test_left[\"identifier\"].nunique()\n",
    "print(unique_segments)\n",
    "for i in range(100):\n",
    "    test_idx.extend([current]*unique_segments)\n",
    "    current += 1\n",
    "test_left[\"test_idx\"] = test_idx\n",
    "\n",
    "assert test_idx[unique_segments-1] != test_idx[unique_segments]\n",
    "test_left[\"supersegment_id\"] = [supersegment_to_id[s] for s in test_left[\"identifier\"]]\n",
    "\n",
    "# Get supersegment features like nearest_counter_id\n",
    "test_left = test_left.merge(supersegments, on=\"supersegment_id\")\n",
    "test_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_test, _ = load_data(city_name, \"test\")\n",
    "# Get counter_id of nodes\n",
    "counts_test = counts_test.merge(nodes_with_counters[[\"node_id\", \"counter_id\"]], on=\"node_id\")\n",
    "counts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join label stub to counters\n",
    "test = test_left.merge(counts_test, left_on=[\"test_idx\", \"nearest_counter_id\"], right_on=[\"test_idx\", \"counter_id\"], how=\"left\")\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert unique_segments * 100 == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test, _ = create_multi_traffic_state(test, traffic_quantiles_list, \"volumes_mdn\", \"test\")\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_h3_variable(test, mode=\"test\")\n",
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some counters have missing data, let's fill this in a dummy way\n",
    "features_to_fill = [\"node_id\", \"counter_id\", \"volumes_gr\", \"volumes_mdn\", \"volumes_sum\", \"volumes_last\"]\n",
    "test[features_to_fill] = test.groupby(\"supersegment_id\")[features_to_fill].transform(lambda x: x.ffill().bfill())\n",
    "assert test.count().sum() == len(test.columns) * len(test)\n",
    "test.count()\n",
    "# TODO doesn't match for Madrid!\n",
    "# Some (required) nodes are missing counters for whole test set. Should we use blacklisting?\n",
    "# test[features_to_fill] = test.groupby(\"supersegment_id\")[features_to_fill].transform(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = merge_pcas(city_name, test, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add city avg volume feats just in case\n",
    "# test[\"city_volumes_gr\"] = test.groupby(\"test_idx\")[\"volumes_gr\"].transform(np.median)\n",
    "# test[\"city_volumes_sum\"] = test.groupby(\"test_idx\")[\"volumes_sum\"].transform(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, quant_feature in enumerate(quantile_feats):\n",
    "    append_static_pred_relative_to_df(test, train, quant_feature, f\"static_pred_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SPEED_FEATURES:\n",
    "    test = test.merge(supersegment_speed_features, left_on=\"supersegment_id\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    assert f in test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_preds = gbm.predict(test[features])\n",
    "test[\"eta\"] = (gbm_preds + test[\"static_pred_0\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"identifier\", \"eta\", \"test_idx\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_folder = data_dir / 'submissions' / model_name / city_name / 'labels'\n",
    "submission_folder.mkdir(exist_ok=True, parents=True)\n",
    "test[[\"identifier\", \"eta\", \"test_idx\"]].to_parquet(submission_folder / f'eta_labels_test_Q_{ITER}.parquet', compression='snappy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:t4c22]",
   "language": "python",
   "name": "conda-env-t4c22-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}