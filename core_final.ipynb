{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm h3 shap hdmedians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbee41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_nodes_with_counters, merge_pcas, split_train_valid, load_edges, load_labels_core\n",
    "from conf import data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb15a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_name = \"melbourne\"\n",
    "\n",
    "traffic_path = data_dir / \"traffic\"\n",
    "\n",
    "model_name = \"core_final\"\n",
    "\n",
    "# No validation set?\n",
    "FULL_TRAIN = True\n",
    "CONTINUE_TRAINING = False\n",
    "CONTINUE_TRAINING_ITER = 690\n",
    "# Running locally on 32GB Mac works with 3e7\n",
    "SAMPLE_ROW_COUNT = None\n",
    "NEIGHBORS_FOR_WEIGHTING = 10\n",
    "\n",
    "class_fractions = {\n",
    "    \"london\": ({\"green\": 0.5367906303432076, \"yellow\": 0.35138063340805714, \"red\": 0.11182873624873524}),\n",
    "    \"madrid\": {\"green\": 0.4976221039083026, \"yellow\": 0.3829591430424158, \"red\": 0.1194187530492816},\n",
    "    \"melbourne\": {\"green\": 0.7018930324884697, \"yellow\": 0.2223245729555099, \"red\": 0.0757823945560204},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495441a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_categorical_features(data):\n",
    "    \n",
    "    feats = [\"oneway\", \"highway\", \"tunnel\"]\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for f in feats:\n",
    "        categories = data[f].astype(\"category\")\n",
    "        cat_codes = categories.cat.codes\n",
    "        data[f\"{f}_cat\"] = cat_codes\n",
    "    \n",
    "    feature_dicts = {}\n",
    "    for f in feats:\n",
    "        feature_dicts[f] = {k: v for k, v in zip(data[f], cat_codes)}\n",
    "    \n",
    "    return data, feature_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb334a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0925c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_parquet(data_dir / f\"road_graph/{city_name}/road_graph_nodes.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526cbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, edge_id_to_int, edge_int_to_id = load_edges(city_name)\n",
    "edges, edge_dicts = create_categorical_features(edges)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get representative point of edge\n",
    "edges = edges.merge(nodes[[\"node_id\", \"x\", \"y\"]], left_on=\"u\", right_on=\"node_id\", how=\"left\")\n",
    "# TODO should we take centre between u and v?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794552b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_with_counters = create_nodes_with_counters(city_name, blacklist=False)\n",
    "nodes_with_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nearest counter for edges which are not immediately at counter\n",
    "from sklearn.neighbors import KDTree, BallTree\n",
    "tree = KDTree(nodes_with_counters[[\"x\", \"y\"]], metric=\"euclidean\")\n",
    "dist, ind = tree.query(edges[[\"x\", \"y\"]], k=NEIGHBORS_FOR_WEIGHTING)\n",
    "edges[\"nearest_counter_id\"] = ind[:,0]\n",
    "edges[\"counter_distance_euclidean\"] = dist[:,0]\n",
    "edges[\"counter_distance_euclidean_mean_all\"] = dist.mean(axis=1)\n",
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1d9c2c",
   "metadata": {},
   "source": [
    "## Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels_core(city_name, edge_id_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d71228",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[\"cc\"] = labels[\"cc\"] - 1\n",
    "labels[\"cc\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8752fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge edge features\n",
    "labels = labels.merge(edges[[\n",
    "    \"edge_int\", \"x\", \"y\", \"counter_distance_euclidean\", \"counter_distance_euclidean_mean_all\", \"parsed_maxspeed\", \"oneway_cat\", \"highway_cat\", \"length_meters\", \"counter_distance\", \"importance\"]], on=\"edge_int\")\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just city average volume features which should be redundant, just in case\n",
    "volume_agg_train = pd.read_parquet(traffic_path / city_name / f\"volume_agg_train.parquet\")\n",
    "labels = labels.merge(volume_agg_train, on=[\"day\", \"t\"], how=\"left\")\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641026ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = merge_pcas(city_name, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge edge target encodings\n",
    "print(\"Merging static target encodings\")\n",
    "cc_distributions = pd.read_parquet(data_dir / \"traffic\" / city_name / \"cc_dist.parquet\")\n",
    "labels = labels.merge(cc_distributions, on=\"edge_int\")\n",
    "print(labels.shape)\n",
    "\n",
    "bomber_feats = pd.read_parquet(data_dir / \"traffic\" / city_name / \"bomber_feats.parquet\")\n",
    "labels = labels.merge(bomber_feats, on=\"edge_int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a68463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform logits to probabilities\n",
    "labels[\"proba_green\"] = np.exp(labels[\"logit_green\"]) / (np.exp(labels[\"logit_green\"]) + np.exp(labels[\"logit_yellow\"]) + np.exp(labels[\"logit_red\"]))\n",
    "labels[\"proba_yellow\"] = np.exp(labels[\"logit_yellow\"]) / (np.exp(labels[\"logit_green\"]) + np.exp(labels[\"logit_yellow\"]) + np.exp(labels[\"logit_red\"]))\n",
    "labels[\"proba_red\"] = np.exp(labels[\"logit_red\"]) / (np.exp(labels[\"logit_green\"]) + np.exp(labels[\"logit_yellow\"]) + np.exp(labels[\"logit_red\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29548e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels.shape)\n",
    "# Drop rows where there was no counter data\n",
    "labels = labels.dropna()\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7f2c0",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039995e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = split_train_valid(city_name, labels)\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5ea52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9347cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # Edge positional features\n",
    "    \"counter_distance_euclidean\",\n",
    "    \"counter_distance_euclidean_mean_all\",\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    # Target encoding features\n",
    "    \"proba_green\",\n",
    "    \"proba_yellow\",\n",
    "    \"proba_red\",\n",
    "    \"proba_vol1\",\n",
    "    \"proba_vol3\",\n",
    "    \"proba_vol5\",\n",
    "    \"mdn_speed\",\n",
    "    \"mdn_free_speed\",\n",
    "    \"count_vol_total\",\n",
    "    \"proba_vol1_traffic0\",\n",
    "    \"proba_vol3_traffic0\",\n",
    "    \"proba_vol5_traffic0\",\n",
    "    \"proba_vol1_traffic1\",\n",
    "    \"proba_vol3_traffic1\",\n",
    "    \"proba_vol5_traffic1\",\n",
    "    \"mdn_speed_traffic0\",\n",
    "    \"mdn_speed_traffic1\",\n",
    "    # These are just city averages\n",
    "    \"volumes_gr\", # \n",
    "    \"volumes_sum\",\n",
    "    \"volumes_last\",\n",
    "    # Edge features\n",
    "    \"edge_int\",\n",
    "    \"parsed_maxspeed\",\n",
    "    \"oneway_cat\",\n",
    "    \"highway_cat\",\n",
    "    \"importance\",\n",
    "    \"length_meters\",\n",
    "    \"counter_distance\",\n",
    "    # Secret sauce: city context PCA features\n",
    "] + [f for f in train.columns if f.startswith(\"PC\")]\n",
    "\n",
    "label = \"cc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5de8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_from_class_fractions(class_fractions):\n",
    "    n = np.sum(class_fractions)\n",
    "    return [n / (c * 3) for c in class_fractions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b022ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = get_weights_from_class_fractions([class_fractions[city_name][c] for c in [\"green\", \"yellow\", \"red\"]])\n",
    "# We use these to weight training samples so that optimizing for logloss becomes equivalent to weighted crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a5fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f60c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FULL_TRAIN:    \n",
    "    train = pd.concat([train, valid])\n",
    "    print(train.shape)\n",
    "    del valid\n",
    "    \n",
    "    init_score_train = train[[\"logit_green\", \"logit_yellow\", \"logit_red\"]]\n",
    "    lgb_set = lgb.Dataset(train[features], train[label], init_score=init_score_train)\n",
    "    \n",
    "    weights_train = [class_weights[l] for l in train[label]]\n",
    "    lgb_set.set_weight(weights_train)\n",
    "else:\n",
    "    init_score_train = train[[\"logit_green\", \"logit_yellow\", \"logit_red\"]]\n",
    "    init_score_valid = valid[[\"logit_green\", \"logit_yellow\", \"logit_red\"]]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train[features], train[label], init_score=init_score_train)\n",
    "    lgb_eval = lgb.Dataset(valid[features], valid[label], reference=lgb_train, init_score=init_score_valid)\n",
    "    \n",
    "    weights_train = [class_weights[l] for l in train[label]]\n",
    "    weights_eval = [class_weights[l] for l in valid[label]]\n",
    "    \n",
    "    # Weight samples to optimize for weighted cross entropy\n",
    "    lgb_train.set_weight(weights_train)\n",
    "    lgb_eval.set_weight(weights_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afeb7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is from a single Optuna run, we optimize only num_leaves a bit and num_iters\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    \"num_classes\": 3,\n",
    "    # Crazy how large we can make this! These are individual decision trees with tens of thousands of leaves\n",
    "    # A smaller number should be less risky though, as the valid loss plateau would span over a larger number of iterations\n",
    "    # But we wanted to save training time here\n",
    "#     \"num_leaves\": 10000,\n",
    "    \"num_leaves\": 5000,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 1.0,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'lambda_l1': 8.544245989665272,\n",
    "    'lambda_l2': 0.09577740930772316,\n",
    "    'min_child_samples': 10,\n",
    "}\n",
    "\n",
    "model_path = data_dir / \"models\" / model_name / city_name\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_model_callback(env):\n",
    "    if env.iteration > 100:\n",
    "        if env.iteration % 10 == 0:\n",
    "            print(\"Saving!\")\n",
    "            env.model.save_model(model_path / f\"model_full_{env.iteration}.lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With 5k/10k leaves, we need very few iterations\n",
    "NO_LGB_ITERS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting training...')\n",
    "if FULL_TRAIN:\n",
    "    if CONTINUE_TRAINING:\n",
    "        print(f\"Continuing training from iter {CONTINUE_TRAINING_ITER}\")\n",
    "    \n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_set,\n",
    "                    num_boost_round=NO_LGB_ITERS,\n",
    "                    valid_sets=[lgb_set],\n",
    "                    callbacks=[save_model_callback],\n",
    "                    init_model=model_path / f\"model_full_{CONTINUE_TRAINING_ITER}.lgb\" if CONTINUE_TRAINING else None,\n",
    "                    verbose_eval=10)\n",
    "else:\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=NO_LGB_ITERS,\n",
    "                    valid_sets=[lgb_train, lgb_eval],\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=200)],\n",
    "                    verbose_eval=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_wrapped(data, model, features):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    X = data.sample(500)[features]\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    shap.initjs()    \n",
    "    shap.summary_plot(shap_values, X)\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\")\n",
    "    \n",
    "shap_wrapped(train, gbm, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.save_model(model_path / f\"model_full_{NO_LGB_ITERS}.lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965648f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e41b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e78f6",
   "metadata": {},
   "source": [
    "## Generate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1562ff3-be4c-4f0f-9068-7ddc11db517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally we want to cherry pick this on the test set (wouldn't work with double blind test set)\n",
    "iters_to_use = 280\n",
    "\n",
    "model_path = data_dir / \"models\" / model_name / city_name / f\"model_full_{iters_to_use}.lgb\"\n",
    "gbm = lgb.Booster(model_file=model_path)\n",
    "print(iters_to_use)\n",
    "# Note that LGB trains separate tree per each logit\n",
    "assert gbm.num_trees() / 3 == iters_to_use+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e917be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = data_dir / \"test\" / city_name / \"input\" / \"counters_test.parquet\"\n",
    "counters_test = pd.read_parquet(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad70a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# For test set, we need to create a submission set of length len(edges) * counters_test[\"test_idx\"].nunique()\n",
    "# Do this in iterations, as direct join returned weird DF shape\n",
    "full_test = []\n",
    "for t in tqdm(range(counters_test[\"test_idx\"].nunique())):\n",
    "    full = edges.copy()\n",
    "    full[\"test_idx\"] = t\n",
    "    full_test.append(full)\n",
    "    \n",
    "full_test = pd.concat(full_test)\n",
    "full_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_agg_test = pd.read_parquet(traffic_path / city_name / f\"volume_agg_test.parquet\")\n",
    "full_test = full_test.merge(volume_agg_test, on=[\"test_idx\"])\n",
    "full_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6694d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test = merge_pcas(city_name, full_test, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test = full_test.merge(cc_distributions, on=\"edge_int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf71f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test = full_test.merge(bomber_feats, on=\"edge_int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51866424",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test[\"proba_green\"] = np.exp(full_test[\"logit_green\"]) / (np.exp(full_test[\"logit_green\"]) + np.exp(full_test[\"logit_yellow\"]) + np.exp(full_test[\"logit_red\"]))\n",
    "full_test[\"proba_yellow\"] = np.exp(full_test[\"logit_yellow\"]) / (np.exp(full_test[\"logit_green\"]) + np.exp(full_test[\"logit_yellow\"]) + np.exp(full_test[\"logit_red\"]))\n",
    "full_test[\"proba_red\"] = np.exp(full_test[\"logit_red\"]) / (np.exp(full_test[\"logit_green\"]) + np.exp(full_test[\"logit_yellow\"]) + np.exp(full_test[\"logit_red\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    assert f in full_test.columns, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "stm = time.time()\n",
    "gbm_preds = gbm.predict(full_test[features], raw_score=True)\n",
    "print(f\"Took {time.time() - stm} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2896267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to init_soce because LGB learns the increment\n",
    "full_preds = gbm_preds + full_test[[\"logit_green\", \"logit_yellow\", \"logit_red\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b962506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save disk space\n",
    "full_test[\"logit_green\"] = full_preds[\"logit_green\"].round(3)\n",
    "full_test[\"logit_yellow\"] = full_preds[\"logit_yellow\"].round(3)\n",
    "full_test[\"logit_red\"] = full_preds[\"logit_red\"].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f75da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test[\"test_idx\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test[\"edge_int\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730290ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = data_dir / \"submissions\" / model_name / city_name / \"labels\" / \"cc_labels_test.parquet\"\n",
    "\n",
    "submission_features = [\n",
    "    \"logit_green\",\n",
    "    \"logit_yellow\",\n",
    "    \"logit_red\",\n",
    "    \"u\",\n",
    "    \"v\",\n",
    "    \"test_idx\"\n",
    "]\n",
    "\n",
    "import time\n",
    "stm = time.time()\n",
    "submission_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "full_test[submission_features].to_parquet(submission_path)\n",
    "print(f\"Took {time.time() - stm} seconds\")\n",
    "\n",
    "full_test[submission_features]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}