{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import load_edges, split_train_valid, proba_to_logit, load_labels_core, load_preprocessed_counters, get_weights_from_class_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "from conf import data_dir\n",
    "city_name = \"melbourne\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-utility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e11d13-70ec-45e0-9ba4-3fb71b9797bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hpw many observations per class do we require\n",
    "sparse_threshold = 2\n",
    "# Use validation set?\n",
    "FULL_TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e5d36-4058-4af4-ae09-faa8f20db07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, edge_id_to_int, edge_int_to_id = load_edges(city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2a32e-8824-4958-88ff-c291ff1c9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping of times to traffic regimes\n",
    "counts = load_preprocessed_counters(city_name, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bac7fe-d88b-42c0-a288-0ca46fcffbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = counts.groupby([\"day\", \"t\"])[\"volumes_last\"].median()\n",
    "high_traffic_threshold = traffic.median()\n",
    "traffic = traffic.reset_index()\n",
    "traffic[\"high_traffic\"] = [1 if v > high_traffic_threshold else 0 for v in traffic[\"volumes_last\"]]\n",
    "del counts\n",
    "traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-upgrade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af6246f3-cc17-4790-b11d-2cbe8860e79d",
   "metadata": {},
   "source": [
    "## Create traffic conditional features based on speed_classes data (the raw source for all labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617fc46-250c-4b83-9f12-8d33315dd5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds = pd.read_parquet(data_dir / \"speed_classes\" / city_name)\n",
    "\n",
    "print(speeds.info())\n",
    "print(speeds.count())\n",
    "\n",
    "speeds[\"edge_id\"] = [f\"{u}_{v}\" for u, v in tqdm(zip(speeds[\"u\"], speeds[\"v\"]))]\n",
    "speeds[\"edge_int\"] = [edge_id_to_int[eid] for eid in tqdm(speeds[\"edge_id\"])]\n",
    "del speeds[\"edge_id\"]\n",
    "\n",
    "if FULL_TRAIN:\n",
    "    speeds_train, speeds_valid = split_train_valid(city_name, speeds)\n",
    "else:\n",
    "    speeds_train = speeds\n",
    "# speeds.shape\n",
    "# Not exactly same shape as labels - looks like a subset (almost identical tho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e478dc-245c-41e6-8552-e0a7e724c7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be94cd1-ab7f-49e4-85bb-5aab3215d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_train = speeds_train.merge(traffic, on=[\"day\", \"t\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a64c4-aefc-4298-baf8-9fcbd2b57fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b5f10-fab0-45af-8f5b-f07d6c072b62",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aced88-4822-432a-a996-8dc186fc8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn_speeds_traffic = speeds_train.groupby([\"edge_int\", \"high_traffic\"])[\"median_speed_kph\"].median().to_dict()\n",
    "vol_distributions_traffic = speeds_train.groupby([\"edge_int\", \"high_traffic\"])[\"volume_class\"].value_counts().to_dict()\n",
    "\n",
    "edges[\"mdn_speed_traffic0\"] = [ mdn_speeds_traffic.get((e, 0)) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "edges[\"mdn_speed_traffic1\"] = [ mdn_speeds_traffic.get((e, 1)) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "\n",
    "for traffic in [0, 1]:\n",
    "    for vol in [1, 3, 5]:\n",
    "        edges[f\"count_vol{vol}_traffic{traffic}\"] = [ vol_distributions_traffic.get((e, traffic, vol), 0) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "\n",
    "edges[\"count_vol_total_traffic0\"] = edges[\"count_vol1_traffic0\"] + edges[\"count_vol3_traffic0\"] + edges[\"count_vol5_traffic0\"]\n",
    "edges[\"count_vol_total_traffic1\"] = edges[\"count_vol1_traffic1\"] + edges[\"count_vol3_traffic1\"] + edges[\"count_vol5_traffic1\"]\n",
    "\n",
    "for traffic in [0, 1]:\n",
    "    for vol in [1, 3, 5]:\n",
    "        edges[f\"proba_vol{vol}_traffic{traffic}\"] = edges[f\"count_vol{vol}_traffic{traffic}\"] / edges[f\"count_vol_total_traffic{traffic}\"]\n",
    "        \n",
    "del mdn_speeds_traffic, vol_distributions_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bad3ff-0edb-473b-ba79-e08ecbcdc145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For these features, we apply a more strict threshold\n",
    "sparse_threshold_traffic = 5\n",
    "sparse_edge_id = (edges[\"count_vol1_traffic0\"] < sparse_threshold_traffic) | (edges[\"count_vol3_traffic0\"] < sparse_threshold_traffic) | (edges[\"count_vol5_traffic0\"] < sparse_threshold_traffic) | (edges[\"count_vol1_traffic1\"] < sparse_threshold_traffic) | (edges[\"count_vol3_traffic1\"] < sparse_threshold_traffic) | (edges[\"count_vol5_traffic1\"] < sparse_threshold_traffic)\n",
    "\n",
    "print(edges.shape)\n",
    "print(edges.loc[sparse_edge_id].shape)\n",
    "\n",
    "feats_to_safeguard = [\"proba_vol1_traffic0\", \"proba_vol3_traffic0\", \"proba_vol5_traffic0\", \"proba_vol1_traffic1\", \"proba_vol3_traffic1\", \"proba_vol5_traffic1\", \"mdn_speed_traffic0\", \"mdn_speed_traffic1\"]\n",
    "safeguarded_vals = edges.loc[sparse_edge_id][feats_to_safeguard].median().to_dict()\n",
    "print(safeguarded_vals)\n",
    "\n",
    "for feat in feats_to_safeguard:\n",
    "    edges.loc[sparse_edge_id, feat] = safeguarded_vals[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7b1be-33fa-4071-b19c-9e3959acfed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3233d6-ae63-4cbf-b83e-664f9b31b5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f194a-ac4c-4ab0-bda9-d31eb2cfcd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36892f13-8ac6-4ff1-af6b-efaa1d9cb24f",
   "metadata": {},
   "source": [
    "## Similar target encoding features, but unconditional on traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508a575-d9df-45b8-9a1a-36a7723544c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdn_speeds = speeds_train.groupby(\"edge_int\")[\"median_speed_kph\"].median().to_dict()\n",
    "free_speeds = speeds_train.groupby(\"edge_int\")[\"free_flow_kph\"].median().to_dict()\n",
    "vol_distributions = speeds_train.groupby(\"edge_int\")[\"volume_class\"].value_counts().to_dict()\n",
    "\n",
    "edges[\"count_vol1\"] = [ vol_distributions.get((e, 1), 0) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "edges[\"count_vol3\"] = [ vol_distributions.get((e, 3), 0) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "edges[\"count_vol5\"] = [ vol_distributions.get((e, 5), 0) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "\n",
    "edges[\"count_vol_total\"] = edges[\"count_vol1\"] + edges[\"count_vol3\"] + edges[\"count_vol5\"]\n",
    "\n",
    "edges[\"proba_vol1\"] = edges[\"count_vol1\"] / edges[\"count_vol_total\"]\n",
    "edges[\"proba_vol3\"] = edges[\"count_vol3\"] / edges[\"count_vol_total\"]\n",
    "edges[\"proba_vol5\"] = edges[\"count_vol5\"] / edges[\"count_vol_total\"]\n",
    "\n",
    "edges[\"mdn_speed\"] = [ mdn_speeds.get(e) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "edges[\"mdn_free_speed\"] = [ free_speeds.get(e) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "\n",
    "# Safeguarding against leakage\n",
    "sparse_edge_id = (edges[\"count_vol1\"] < sparse_threshold) | (edges[\"count_vol3\"] < sparse_threshold) | (edges[\"count_vol5\"] < sparse_threshold)\n",
    "\n",
    "print(edges.shape)\n",
    "\n",
    "print(edges.loc[sparse_edge_id].shape)\n",
    "\n",
    "feats_to_safeguard = [\"proba_vol1\", \"proba_vol3\", \"proba_vol5\", \"mdn_speed\", \"mdn_free_speed\"]\n",
    "safeguarded_vals = edges.loc[sparse_edge_id][feats_to_safeguard].median().to_dict()\n",
    "safeguarded_vals\n",
    "\n",
    "for feat in feats_to_safeguard:\n",
    "    edges.loc[sparse_edge_id, feat] = safeguarded_vals[feat]\n",
    "\n",
    "print(edges.count())\n",
    "\n",
    "edges[[\n",
    "    \"edge_int\",\n",
    "    \"count_vol_total\",\n",
    "    \"proba_vol1\",\n",
    "    \"proba_vol3\",\n",
    "    \"proba_vol5\",\n",
    "    \"mdn_speed\",\n",
    "    \"mdn_free_speed\",\n",
    "    \"proba_vol1_traffic0\",\n",
    "    \"proba_vol3_traffic0\",\n",
    "    \"proba_vol5_traffic0\",\n",
    "    \"proba_vol1_traffic1\",\n",
    "    \"proba_vol3_traffic1\",\n",
    "    \"proba_vol5_traffic1\",\n",
    "    \"mdn_speed_traffic0\",\n",
    "    \"mdn_speed_traffic1\"\n",
    "]].to_parquet(data_dir / \"traffic\" / city_name / \"bomber_feats.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70951119-5a60-4278-b42d-f90122490dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d21c82b-8114-400c-aa37-213ab16750da",
   "metadata": {},
   "source": [
    "## Finally we calculate traffic unconditional class congestion logits which we will use as the LightGBM initialization score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97ab31-afda-45cb-9215-1208d7715f87",
   "metadata": {},
   "source": [
    "Note that we need to scale the raw probabilities by normalized class weights when converting to logits, in order for them to optimize our custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels_core(city_name, edge_id_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FULL_TRAIN:\n",
    "    train, valid = split_train_valid(city_name, labels)\n",
    "    del labels, valid\n",
    "else:\n",
    "    train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_distributions = train.groupby(\"edge_int\")[\"cc\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(\"edge_int\")[\"cc\"].value_counts().quantile([0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"cc\"] == 1].groupby([\"edge_int\", \"cc\"])[\"cc\"].count().quantile([0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"cc\"] == 2].groupby([\"edge_int\", \"cc\"])[\"cc\"].count().quantile([0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"cc\"] == 3].groupby([\"edge_int\", \"cc\"])[\"cc\"].count().quantile([0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-external",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[\"count_green\"] = [ cc_distributions.get((e, 1), 0) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "edges[\"count_yellow\"] = [ cc_distributions.get((e, 2), 0) for e in tqdm(edges[\"edge_int\"]) ]\n",
    "edges[\"count_red\"] = [ cc_distributions.get((e, 3), 0) for e in tqdm(edges[\"edge_int\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[\"count_total\"] = edges[\"count_green\"] + edges[\"count_yellow\"] + edges[\"count_red\"]\n",
    "\n",
    "edges[\"proba_green\"] = edges[\"count_green\"] / edges[\"count_total\"]\n",
    "edges[\"proba_yellow\"] = edges[\"count_yellow\"] / edges[\"count_total\"]\n",
    "edges[\"proba_red\"] = edges[\"count_red\"] / edges[\"count_total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_edge_id = (edges[\"count_green\"] < sparse_threshold) | (edges[\"count_yellow\"] < sparse_threshold) | (edges[\"count_red\"] < sparse_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.loc[sparse_edge_id].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.loc[sparse_edge_id][[\"proba_green\", \"proba_yellow\", \"proba_red\"]].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-transportation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_fractions = {\n",
    "    \"london\": ({\"green\": 0.5367906303432076, \"yellow\": 0.35138063340805714, \"red\": 0.11182873624873524}),\n",
    "    \"madrid\": {\"green\": 0.4976221039083026, \"yellow\": 0.3829591430424158, \"red\": 0.1194187530492816},\n",
    "    \"melbourne\": {\"green\": 0.7018930324884697, \"yellow\": 0.2223245729555099, \"red\": 0.0757823945560204},\n",
    "}\n",
    "\n",
    "class_weights = get_weights_from_class_fractions([class_fractions[city_name][c] for c in [\"green\", \"yellow\", \"red\"]])\n",
    "norm_class_weights = np.array(class_weights) / np.sum(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try to stop leakage - Overwrite sparse edges with fallback\n",
    "feats_to_safeguard = [\"proba_green\", \"proba_yellow\", \"proba_red\"]\n",
    "safeguarded_vals = edges.loc[sparse_edge_id][feats_to_safeguard].median().to_dict()\n",
    "print(safeguarded_vals)\n",
    "\n",
    "for feat in feats_to_safeguard:\n",
    "    edges.loc[sparse_edge_id, feat] = safeguarded_vals[feat]\n",
    "    \n",
    "# Overwrite sparse edges with fallback - previous one\n",
    "# edges.loc[edges[\"count_total\"] < 30, \"proba_green\"] = low_traffic_edge_distributions[city_name][\"green\"]\n",
    "# edges.loc[edges[\"count_total\"] < 30, \"proba_yellow\"] = low_traffic_edge_distributions[city_name][\"yellow\"]\n",
    "# edges.loc[edges[\"count_total\"] < 30, \"proba_red\"] = low_traffic_edge_distributions[city_name][\"red\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[\"logit_green\"] = [proba_to_logit(p*norm_class_weights[0]) for p in tqdm(edges[\"proba_green\"])]\n",
    "edges[\"logit_yellow\"] = [proba_to_logit(p*norm_class_weights[1]) for p in tqdm(edges[\"proba_yellow\"])]\n",
    "edges[\"logit_red\"] = [proba_to_logit(p*norm_class_weights[2]) for p in tqdm(edges[\"proba_red\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-decision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[[\"logit_green\", \"logit_yellow\", \"logit_red\"]].quantile(q=[0.0001, 0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[[\"logit_green\", \"logit_yellow\", \"logit_red\"]].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[[\"logit_green\", \"logit_yellow\", \"logit_red\"]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-acquisition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[[\"edge_int\", \"logit_green\", \"logit_yellow\", \"logit_red\"]].to_parquet(data_dir / \"traffic\" / city_name / \"cc_dist.parquet\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.r5.24xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
